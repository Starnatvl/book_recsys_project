# Прототип рекомендательной системы книг (Goodbooks-10k)

Этот репозиторий содержит решение двух этапов проекта по построению рекомендательной системы для сервиса чтения книг. Проект демонстрирует эволюцию от классических методов (EDA, SVD, Content-Based) до гибридной системы с использованием нейросетей (NCF). В ходе работы была обнаружена и устранена утечка данных (data leakage), что позволило получить достоверные метрики.

# Проект: Гибридная рекомендательная система книг

## 1. Цель проекта
Разработать рекомендательную систему, которая предсказывает, какие книги могут понравиться пользователю, на основе его прошлых оценок и характеристик книг. В проекте объединены классические алгоритмы коллаборативной фильтрации, контентный подход и нейросетевая архитектура для повышения качества и устойчивости рекомендаций.

## 2. Данные
Использован набор данных Goodbooks-10k, включающий:
- `ratings.csv` – 981 756 оценок (пользователь, книга, оценка от 1 до 5);
- `books.csv` – информация о 10 000 книгах (название, автор, средний рейтинг, количество оценок и др.);
- `tags.csv` и `book_tags.csv` – теги, присвоенные книгам пользователями.

После загрузки проведена первичная проверка качества: типы данных, пропуски, дубликаты. Обнаружено 1644 дубликата в таблице оценок (один пользователь мог несколько раз оценить одну книгу). Дубликаты удалены с сохранением последней оценки. Пропуски в названиях книг заполнены основным названием.

## 3. Разведочный анализ (EDA)
Построены графики:
- распределение оценок (большинство оценок – 4 и 5);
- активность пользователей (логарифмическая шкала) – многие пользователи оставили мало оценок;
- популярность книг (long tail) – небольшое число книг имеет много оценок;
- топ-10 самых популярных тегов.

Разреженность матрицы пользователь–книга составила 99,8%, что характерно для реальных систем.

## 4. Конструирование признаков
Для обогащения данных созданы статистические признаки:
- для каждого пользователя: средняя оценка, количество оценок, стандартное отклонение его оценок;
- для каждой книги: средняя оценка, количество оценок, стандартное отклонение, а также взвешенный рейтинг по формуле IMDb (учитывающий количество голосов).

Эти признаки в дальнейшем могут использоваться моделями (хотя в текущей реализации они добавлены в датафреймы, но напрямую не подаются в нейросеть; они служат основой для будущих улучшений).

## 5. Модели

### 5.1. Базовая модель популярности (Popularity)
Книги ранжируются по взвешенному рейтингу (IMDB-формула). Модель не учитывает индивидуальные предпочтения, служит нижней границей качества.

### 5.2. Контентная модель (Content-based)
На основе объединённого текстового поля «название + теги» строится TF-IDF матрица и вычисляется косинусное сходство между книгами. Для пользователя рекомендации формируются как средняя похожесть книг из его истории на книги-кандидаты. Модель хорошо работает для новых книг, но не учитывает поведение других пользователей.

### 5.3. Коллаборативная фильтрация на основе элементов (Item-Based CF)
Строится матрица пользователь–книга, затем для каждой книги ищутся ближайшие соседи по косинусной мере. Оценка пользователя для книги вычисляется как среднее сходство этой книги с книгами, которые пользователь уже оценил. Модель показала наилучшие результаты среди всех.

### 5.4. Матричная факторизация (SVD)
Использована реализация из библиотеки Surprise. SVD раскладывает матрицу оценок на скрытые факторы пользователей и книг. Модель даёт высокую точность, но страдает от холодного старта.

### 5.5. Нейросетевая модель NCF (Neural Collaborative Filtering)
Реализована архитектура, объединяющая GMF (обобщённая матричная факторизация) и MLP (многослойный перцептрон). Эмбеддинги пользователей и книг размерности 50 конкатенируются и проходят через два полносвязных слоя. Модель обучалась 3 эпохи с MSE. На валидации достигнута ошибка около 0.81. Нейросеть способна улавливать нелинейные взаимодействия, но требует больше данных и тонкой настройки.

### 5.6. Гибридная модель (Hybrid)
Объединяет предсказания всех пяти моделей с весами (SVD – 0.3, NCF – 0.3, Content – 0.2, ItemCF – 0.2). Для новых пользователей (холодный старт) используется только модель популярности. Добавлен небольшой случайный шум для разнообразия.

## 6. Исправление утечки данных
В первоначальной версии проекта признаки пользователей и книг, а также матрица для Item-Based CF были построены на всех данных, включая тестовую выборку. Это приводило к завышенным и недостоверным метрикам. После ревью код был скорректирован: теперь все вычисления выполняются исключительно на тренировочных данных (`train_df`). Метрики, представленные ниже, получены после исправления и являются честными.

## 7. Оценка качества
Для каждой модели рассчитаны метрики Precision@10, Recall@10 и nDCG@10 на тестовой выборке (20% данных). Оценка проводилась на 150 самых активных пользователях, для каждого формировался список кандидатов из книг, которые он оценил в тесте, плюс случайные книги.

Результаты:

| Модель       | Precision@10 | Recall@10 | nDCG@10 |
|--------------|--------------|-----------|---------|
| Popularity   | 0.3267       | 0.1264    | 0.3419  |
| SVD          | 0.5420       | 0.2286    | 0.5509  |
| NCF          | 0.3747       | 0.1466    | 0.3703  |
| Content      | 0.3073       | 0.1134    | 0.2932  |
| ItemCF       | 0.6393       | 0.2380    | 0.6535  |
| Hybrid       | 0.4800       | 0.1956    | 0.4998  |

## 8. Анализ результатов
- **Item-Based CF** показал лучшие результаты по всем метрикам. Это подтверждает, что косинусное сходство между книгами эффективно улавливает совместные предпочтения пользователей. Модель хорошо использует информацию о том, какие книги часто оцениваются вместе.
- **SVD** занимает второе место, демонстрируя силу матричной факторизации для разреженных данных. Несмотря на отсутствие дополнительных признаков, SVD даёт высокую точность.
- **Гибридная модель** уступает лучшей отдельной модели, но при этом она более устойчива и разнообразна. В условиях холодного старта (новые пользователи) гибрид автоматически переключается на популярность, что повышает его практическую ценность.
- **Нейросетевая модель NCF** пока отстаёт от классических методов. Вероятно, для её улучшения требуется больше эпох обучения, настройка гиперпараметров или использование дополнительных признаков (например, средних оценок пользователей и книг).
- **Контентная модель** показывает результат на уровне популярности. Текстовые признаки (названия и теги) сами по себе недостаточно информативны для точных предсказаний, но могут быть полезны для новых книг, по которым ещё нет оценок.
- **Модель популярности** служит нижней границей качества и ожидаемо уступает персонализированным подходам.

## 9. Выводы о доверии к модели
Разработанная гибридная система не является «чёрным ящиком» – её поведение можно интерпретировать через веса отдельных компонентов. Высокие метрики Item-Based и SVD говорят о том, что коллаборативная информация (поведение пользователей) критически важна для точности. Гибрид, хоть и немного уступает лучшей модели, обеспечивает более гладкие и разнообразные рекомендации за счёт балансировки и подмешивания популярности для новых пользователей. На практике это означает, что пользователь с большей вероятностью получит релевантные, но при этом не слишком однообразные предложения.

Модель можно улучшить, дообучив нейросеть, добавив больше признаков (например, возраст пользователя, жанровые предпочтения) и оптимизировав веса гибрида на валидационной выборке. Тем не менее, уже в текущем виде система способна давать персонализированные рекомендации, существенно превосходящие по качеству простой топ популярных книг.

## 10. Заключение
В проекте реализован полный цикл разработки рекомендательной системы: от загрузки и очистки данных до обучения нескольких моделей и их объединения в гибрид. После исправления утечки данных получены достоверные метрики, подтверждающие эффективность коллаборативных методов. Гибридная архитектура позволяет сочетать преимущества различных алгоритмов и является предпочтительным выбором для реальных сервисов.

---
**Запуск:**
1. Установите зависимости: `pip install -r requirements.txt`
2. Запустите ноутбук в папке `notebook/`
